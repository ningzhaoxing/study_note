# 1. 实习
## 1.1 触发器模型设计与演进

1. 你提到 `DataFetcher` 采用了策略模式去区分不同的拉取逻辑，能具体说说你在 Go 中是如何实现策略模式的吗？接口和实现的关系是怎样定义的？

	策略模式是定义一系列算法的方法。所有实现都完成相同的工作，只是完成的策略不同。在 go 中可以用 type 关键字定义 interface，在接口中声明具体的方法签名。然后不同的策略类实现该接口即可。定义 `type DataFetcher interface { Fetch(...) }`，由 `DirectFetcher` 和 `IndirectFetcher` 两种策略实现

2. 在你提到的“基于元数据的拉取”中，具体是如何通过第一次拉取的响应构造下一次请求参数的？有没有涉及表达式解析或动态配置？

	基于`expr-lang`表达式引擎解析实现，用户在配置时需要配置表达式指明从响应数据中的哪个字段中提取出对应的事件ID。在提取过程中，将响应 json 字符串解析到 `map[string]interface{}` ，将其嵌入到 `data` 字段中。然后编译执行表达式得到结果。样保证了配置的灵活性，表达式可动态解析用户输入，不需要硬编码字段路径

3. 当补充拉取接口出现失败或延迟时，你是如何保证触发器执行的幂等性与一致性的？

	这个问题我没考虑到，该如何回答？我的思路是在补充拉取接口成功后，将事件ID持久化到数据库。之后拉取到的事件列表，根据该事件ID进行去重。

4. 在 pull 模型下的轮询触发中，你们是如何处理 **checkpoint** 或 **游标（cursor）** 的？

	`checkpoint` 是用户配置表达式表示以哪个字段作为 checkpoint，并配置到对应的查询参数里面。同时在 pull 模型下，用户需要配置按哪个字段进行排序和排序规则（默认按照配置的实体ID进行排序）。在每次拉取数据结束后，对事件列表进行排序，checkpoint 则保存了排序后的第一个数据和最后一个数据并持久化到数据库，在拉取前先从数据库把 checkpoint 查出来，通过用户配置的表达式计算对应的值作为查询条件。

5. 在 push 模式下，事件是异步推送的，你们如何保证事件消费的顺序性或去重？

	因为消费事件是单线程处理的，不是并发处理，所以在消费端不会出现顺序性问题。去重策略会在通过持久化之前消费的事件ID，在每次消费后对已存在数据库的事件进行去重。

6. 你提到方案二是通过「数据丰富器」解耦实现的。请你具体描述一下这个“数据丰富器”的职责边界，它和 `DataFetcher` 在模型语义上有什么不同？

	数据拉取器负责【拿回来东西】，数据丰富器负责将【让拿回来的东西完整】。保持数据拉取器领域语义的纯粹，同时数据丰富器成为可独立扩展、复用的行为。

7. 为什么团队最终选择方案二？你觉得它的领域模型优势体现在哪？

	我们认为触发器消费得到事件就已经完成其职责，只不过获取到的事件不是我们想要的完整事件，只需要进行一次丰富的过程。它的设计不仅仅可以帮助触发器丰富数据，同时也可以被其他模型所复用。

8. 在这个模型演进过程中，你是如何判断“**哪些逻辑应该属于领域层，哪些属于应用层**”的？能举个具体的判断例子吗？

	我一般的判断逻辑是，用于需要定义业务概念的行为放在领域层实现；需要协调模型、或调用外部依赖的应放在应用层。“数据丰富” 的动作更多是为了补全数据供上层应用使用，并不影响触发器的核心领域语义。

9. 如果未来 ** Gmail 的事件机制再发生变化**（比如提供批量实体接口），你设计的方案是否可以平滑兼容？

	这个问题我在设计的时候也考虑过。可以兼容。无论是单独实体接口还是批量实体接口，默认都可以按每次调用发送一个实体ID进行获取。未来若支持批量接口，可以在 DataEnricher 内新增批量策略，不影响领域层模型结构

10. 你刚开始提到自己“不熟悉模型设计流程”，那你是如何**在时间紧的情况下快速提升理解和产出的**？

	- 以问题为驱动看模型或技术文档。自己先从产品形态的角度上，自己配置一个触发器，完整跑一遍，想一下是自己大概会怎么设计、分成哪些模块。然后再去看模型设计文档、以及具体代码，效率会更高一些，而且也更加有兴趣。
	- 费曼学习法。给项目负责人去串讲一遍，讲清楚现在的所有理解，同时暴露出自己的盲点或错误的点，进一步完善学习。

11. 你在设计 “Redis + RocketMQ + MySQL” 三层架构时，**如何保证数据一致性**？比如 MQ 消息丢失或重复消费的情况。

	这个问题我当时考虑过，不过 mt 说这个日志调试不用那么复杂，对数据一致性不会要求很高，而且消息丢失或重复的概率也很小，架构上设计不用那么复杂。
	不过该问题一般从生产端和消费端去考虑，Broker 是集群部署，消息持久化到磁盘很难丢失数据。生产端确保消息不丢失最好同步生产并确认收到ACK，再进行之后的逻辑，如果超时没收到ACK则进行重试，保证消息至少投递一次。消费端关闭自动 ack，在事务处理结束后手动ack。消息重复通过在消费端 `trace_id` 唯一约束来保证不会重复消费。
	另外在 RocketMQ 层面开启消息持久化与重试机制可进一步增强可靠性。


这是我回答的问题，其中3.6.8.10这四个问题我不太会，请你帮我分析回答一下。然后对其他问题你看下是否有错误或需要补缺的地方，校验一下。然后对我的回答再进行追问
